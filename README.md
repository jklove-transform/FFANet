# FFANet
Abstract
Medical images are an important means to assist doctors in making judgments. For the problem that it is difficult to segment various complex tissue structures in medical images, we propose a segmentation method based on feature aggregation. Firstly, our method adopts VoVNet as the backbone and outputs multi-scale features. Secondly, we use the multi-scale features aggregation module to extract context information fully. Finally, we adopt an attention module to consider the relevance of each spatial and channel. Through the experiments conduct on two datasets, the proposed model scores a dice coefficient of 90.90$\%$ and 86.10$\%$. Results show that our network can segment the target area well in the gray image and RGB image and outperforms the existing methodologies.
